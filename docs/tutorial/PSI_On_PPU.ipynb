{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4f5fec-1a5c-4b6f-b583-fb369472e94b",
   "metadata": {},
   "source": [
    "# PSI On PPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b632d8-b12f-44a1-8a75-5d9c0a704a38",
   "metadata": {},
   "source": [
    "PSI([Private Set Intersection](https://en.wikipedia.org/wiki/Private_set_intersection))是一种使用密码学方法，获取两份数据内容的交集的算法。PSI过程中不泄露任务交集以外的信息。隐私求交技术可解决需要进行数据合作的双方需要获取、分析数据的交集，同时不希望泄露无关内容的问题，通常在联合营销等场景中被应用。\n",
    "\n",
    "PPU实现了以下两种协议：\n",
    "- [ECDH](https://ieeexplore.ieee.org/document/6234849/)：半诚实协议，基于公钥加密，适合小规模数据集\n",
    "- [KKRT](https://eprint.iacr.org/2016/799.pdf)：半诚实协议，基于cuckoo hashing和OT，适合大规模数据集\n",
    "\n",
    "在开始之前，我们需要对环境进行初始化。以下在单机创建了alice, bob, carol三个节点以模拟多个参与方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7c4fa2-ea20-4e0d-b1ad-648cce23e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "sf.init(['alice', 'bob', 'carol'], num_cpus=8, log_to_driver=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0a08b-3aa4-4fa6-9e1d-0caba207bdf5",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c16f07-1c67-4bad-af70-d8a4fe9266f3",
   "metadata": {},
   "source": [
    "首先，我们需要一份数据集用于构建两方、三方垂直切分的场景。为了简单起见，这里使用[iris](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)数据集，我们为其添加两列用于后续单列和多列求交的演示\n",
    "- uid：样本唯一ID\n",
    "- month：模拟样本按月生成的场景，前50%样本是1月生成，后50%样本是2月生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f0a010-0a2e-4ee2-996a-169d7cb2731d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>uid</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>Jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>145</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>146</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>147</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>148</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>149</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     uid month  \n",
       "0      0   Jan  \n",
       "1      1   Jan  \n",
       "2      2   Jan  \n",
       "3      3   Jan  \n",
       "4      4   Jan  \n",
       "..   ...   ...  \n",
       "145  145   Feb  \n",
       "146  146   Feb  \n",
       "147  147   Feb  \n",
       "148  148   Feb  \n",
       "149  149   Feb  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data, target = load_iris(return_X_y=True, as_frame=True)\n",
    "data['uid'] = np.arange(len(data)).astype('str')\n",
    "data['month'] = ['Jan'] * 75 + ['Feb'] * 75\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb263ff-e8a3-4066-ab30-ea01030a9f18",
   "metadata": {},
   "source": [
    "在实际场景中，样本数据是由各个参与方提供的，并且需要提前约定好用于求交的字段：\n",
    "- 求交字段可以是单个或多个，但是必须是各方共同拥有\n",
    "- 求交字段必须唯一，如有重复，需要提前去重\n",
    "\n",
    "例如，以下是由alice提供的用于PSI求交的数据，求交字段为`uid`和`month`，可以看到[1, 'Jan']有重复，在PSI求交前需要去重。\n",
    "```\n",
    "alice.csv\n",
    "---------\n",
    "uid   month   c0\n",
    "1     Jan     5.8\n",
    "2     Jan     5.4\n",
    "1     Jan     5.8\n",
    "1     Feb     7.4\n",
    "```\n",
    "去重后的数据为\n",
    "```\n",
    "alice.csv\n",
    "---------\n",
    "uid   month   c0\n",
    "1     Jan     5.8\n",
    "2     Jan     5.4\n",
    "1     Feb     7.4\n",
    "```\n",
    "\n",
    "我们对iris数据进行三次随机采样以模拟alice, bob, carol提供的数据，此时三份数据处于未对齐状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037542dd-7945-4665-9d6a-7d805ea52b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('.data', exist_ok=True)\n",
    "da, db, dc = data.sample(frac=0.9), data.sample(frac=0.8), data.sample(frac=0.7)\n",
    "\n",
    "da.to_csv('.data/alice.csv', index=False)\n",
    "db.to_csv('.data/bob.csv', index=False)\n",
    "dc.to_csv('.data/carol.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54451db-c9ba-45ca-877b-06619e03215f",
   "metadata": {},
   "source": [
    "## 两方PSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12512f-4889-4f71-a539-e5bb7f56a9a5",
   "metadata": {},
   "source": [
    "我们在物理设备上虚拟出三个逻辑设备\n",
    "- alice, bob：PYU设备，负责参与方本地的明文计算\n",
    "- ppu：PPU设备，由alice和bob构成，负责两方的密文计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff729adb-f89a-499d-999f-6d884f2203e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "ppu = sf.PPU(sf.utils.testing.cluster_def(['alice', 'bob']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b161a-5aa9-4d06-b866-48b25273e48b",
   "metadata": {},
   "source": [
    "### 单列求交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12444e3-1da0-426e-add2-609770f8f259",
   "metadata": {},
   "source": [
    "接下来，我们使用`uid`对两方数据进行求交，PPU提供了`psi_csv`以csv文件作为输入，生成求交后的csv文件，默认使用KKRT协议。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec15656-51c1-4498-9f78-b2bcfd5168fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path = {alice: '.data/alice.csv', bob: '.data/bob.csv'}\n",
    "output_path = {alice: '.data/alice_psi.csv', bob: '.data/bob_psi.csv'}\n",
    "ppu.psi_csv('uid', input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef80302-548f-4277-a460-fee0a07b7728",
   "metadata": {},
   "source": [
    "为了校验结果的正确性，我们使用[pandas.DataFrame.join](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html)对da, db进行inner join。可以看到，两方数据已经按照`uid`进行了对齐，并依据其字典顺序进行了排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec091c3a-83bc-41f4-85d5-351c9d98c643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>uid</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>100</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>101</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>102</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>103</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>104</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>94</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>96</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>97</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>98</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>99</td>\n",
       "      <td>Feb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  6.3               3.3                6.0               2.5   \n",
       "1                  5.8               2.7                5.1               1.9   \n",
       "2                  7.1               3.0                5.9               2.1   \n",
       "3                  6.3               2.9                5.6               1.8   \n",
       "4                  6.5               3.0                5.8               2.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "101                5.6               2.7                4.2               1.3   \n",
       "102                5.7               2.9                4.2               1.3   \n",
       "103                6.2               2.9                4.3               1.3   \n",
       "104                5.1               2.5                3.0               1.1   \n",
       "105                5.7               2.8                4.1               1.3   \n",
       "\n",
       "     uid month  \n",
       "0    100   Feb  \n",
       "1    101   Feb  \n",
       "2    102   Feb  \n",
       "3    103   Feb  \n",
       "4    104   Feb  \n",
       "..   ...   ...  \n",
       "101   94   Feb  \n",
       "102   96   Feb  \n",
       "103   97   Feb  \n",
       "104   98   Feb  \n",
       "105   99   Feb  \n",
       "\n",
       "[106 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = da.join(db.set_index('uid'), on='uid', how='inner', rsuffix='_bob', sort=True)\n",
    "expected = df[da.columns].astype({'uid': 'int64'}).reset_index(drop=True)\n",
    "\n",
    "da_psi = pd.read_csv('.data/alice_psi.csv')\n",
    "db_psi = pd.read_csv('.data/bob_psi.csv')\n",
    "\n",
    "pd.testing.assert_frame_equal(da_psi, expected)\n",
    "pd.testing.assert_frame_equal(db_psi, expected)\n",
    "\n",
    "da_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1015b1-4062-4f40-8c5b-3b3e346cd4d2",
   "metadata": {},
   "source": [
    "### 多列求交"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bdf77c-dd58-4053-a3f4-f69659c8c96e",
   "metadata": {},
   "source": [
    "我们也可以使用多个字段进行求交，以下演示了使用`uid`和`month`对两方数据进行求交。在实现上，多个字段被拼接成一个字符串，因此请保证多列复合主键(Composite Primary Key)没有重复。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db24b582-ef58-4791-89d5-074be619d23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ppu.psi_csv(['uid', 'month'], input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b34956-48c7-4e0f-bb6a-013508866267",
   "metadata": {},
   "source": [
    "同样的，我们使用pandas.DataFrame.join验证结果正确性，可以看到，两方数据已经按照`uid`和`month`进行了对齐，并依据其字典顺序进行了排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aebb3a76-977b-4856-b17d-066fd43230c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = da.join(db.set_index(['uid', 'month']), on=['uid', 'month'], how='inner', rsuffix='_bob', sort=True)\n",
    "expected = df[da.columns].astype({'uid': 'int64'}).reset_index(drop=True)\n",
    "\n",
    "da_psi = pd.read_csv('.data/alice_psi.csv')\n",
    "db_psi = pd.read_csv('.data/bob_psi.csv')\n",
    "\n",
    "pd.testing.assert_frame_equal(da_psi, expected)\n",
    "pd.testing.assert_frame_equal(db_psi, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f2dc4-c6c8-409a-b83d-fa15661def83",
   "metadata": {},
   "source": [
    "## 三方PSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d884a3-4c6b-47ac-8526-ff486e89bcd4",
   "metadata": {},
   "source": [
    "首先，我们增加一个第三方`carol`，并为其创建一个PYU设备，同时创建一个由三方构建的PPU设备。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb7050f-70e4-4dc6-9f07-b19b8aeb69bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "carol = sf.PYU('carol')\n",
    "ppu_3pc = sf.PPU(sf.utils.testing.cluster_def(['alice', 'bob', 'carol']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee3d13d-c648-4072-9ebd-c50787701262",
   "metadata": {},
   "source": [
    "然后，以`uid`和`month`为复合主键进行三方求交，需要注意的是，三方求交暂时只支持ECDH协议。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f58d96-ef7c-411d-9cc4-524ef1c0dd44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path = {alice: '.data/alice.csv', bob: '.data/bob.csv', carol: '.data/carol.csv'}\n",
    "output_path = {alice: '.data/alice_psi.csv', bob: '.data/bob_psi.csv', carol: '.data/carol_psi.csv'}\n",
    "ppu_3pc.psi_csv(['uid', 'month'], input_path, output_path, protocol='ecdh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17461ac1-1409-45ef-a513-ecfe6482feb8",
   "metadata": {},
   "source": [
    "同样的，我们使用pandas.DataFrame.join验证结果正确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6ea04f0-6b8a-40d7-b07a-06e926884261",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['uid', 'month']\n",
    "df = da.join(db.set_index(keys), on=keys, how='inner', rsuffix='_bob', sort=True).join(\n",
    "    dc.set_index(keys), on=keys, how='inner', rsuffix='_carol', sort=True)\n",
    "expected = df[da.columns].astype({'uid': 'int64'}).reset_index(drop=True)\n",
    "\n",
    "da_psi = pd.read_csv('.data/alice_psi.csv')\n",
    "db_psi = pd.read_csv('.data/bob_psi.csv')\n",
    "dc_psi = pd.read_csv('.data/carol_psi.csv')\n",
    "\n",
    "pd.testing.assert_frame_equal(da_psi, expected)\n",
    "pd.testing.assert_frame_equal(db_psi, expected)\n",
    "pd.testing.assert_frame_equal(dc_psi, expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4bb1ed-2530-46c4-b540-8c779dd93439",
   "metadata": {},
   "source": [
    "## What's Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55afbe9a-2855-41d6-b867-ec61c4ba4d20",
   "metadata": {},
   "source": [
    "OK！通过本教程，我们已经了解了如何通过PPU进行两方和三方数据求交。完成数据求交后，我们可以在对齐后的数据集上进行机器学习建模\n",
    "- [Logistic Regression On PPU](./LR_On_PPU.ipynb)：使用JAX在PPU上进行逻辑回归建模\n",
    "- Neural Network on PPU：使用JAX在PPU进行神经网络建模\n",
    "- Basic Split Learning：使用TensorFlow和拆分学习进行神经网络建模"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
